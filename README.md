# Speech Emotion Recognition and Sound Classification

## Overview

The **Speech Emotion Recognition and Sound Classification** project aims to classify emotions from speech signals and categorize various sounds into predefined classes. This machine learning project leverages advanced algorithms and techniques in audio processing to achieve high accuracy in recognizing and classifying emotions from speech, as well as identifying different types of sounds.

## Features

- **Emotion Recognition**: Detects and classifies emotions such as happiness, sadness, anger, and surprise from audio recordings of speech.
- **Sound Classification**: Identifies and categorizes various non-speech sounds into predefined classes (e.g., environmental sounds, mechanical noises).
- **Preprocessing**: Includes audio feature extraction techniques such as Mel-Frequency Cepstral Coefficients (MFCCs) and spectrograms.
- **Model Training**: Utilizes machine learning models like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for classification tasks.
- **Evaluation**: Provides performance metrics such as accuracy, precision, recall, and F1-score for both emotion recognition and sound classification tasks.

## Requirements

- Python 3.7+
- Libraries: TensorFlow, Keras, librosa, NumPy, pandas, scikit-learn
